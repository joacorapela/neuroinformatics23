\documentclass[12pt]{article}

\usepackage{natbib}
\usepackage{apalike}
\usepackage[hypertexnames=false,colorlinks=true,breaklinks]{hyperref}
\usepackage{graphicx}
\usepackage[shortlabels]{enumitem}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[title]{appendix}
\usepackage[margin=1in]{geometry}
\usepackage{verbatim}
\usepackage[many]{tcolorbox}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}

\tcolorboxenvironment{theorem}{
    colback=blue!5!white,
    boxrule=0pt,
    boxsep=1pt,
    left=2pt,right=2pt,top=2pt,bottom=2pt,
    oversize=2pt,
    sharp corners,
    before skip=\topsep,
    after skip=\topsep,
}

\tcolorboxenvironment{definition}{
    colback=blue!5!white,
    boxrule=0pt,
    boxsep=1pt,
    left=2pt,right=2pt,top=2pt,bottom=2pt,
    oversize=2pt,
    sharp corners,
    before skip=\topsep,
    after skip=\topsep,
}

\tcolorboxenvironment{lemma}{
    colback=blue!5!white,
    boxrule=0pt,
    boxsep=1pt,
    left=2pt,right=2pt,top=2pt,bottom=2pt,
    oversize=2pt,
    sharp corners,
    before skip=\topsep,
    after skip=\topsep,
}

\def\fig_width{3.5in}
\title{Report
\href{https://drive.google.com/file/d/1r90rlJpFKilQmNj1h27gmZdyi-RJeCq_/view?usp=share_link}{worksheet 5}}
\author{Joaqu\'{i}n Rapela}

\begin{document}

\maketitle

\section*{Exercise 1: z-scored binned spikes}

Figure~\ref{fig:zscores_unsorted} shows the zscores of the binned spikes of all
neurons (bin size=1~sec, unsorted neurons). I chose \texttt{zmin} and
\texttt{zmax} as the 1\% and 99\% percentiles of the zscores distribution,
because, as shown below, negative z-values are informative.


\begin{figure}[H]
    \begin{center}
        \href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_binSize_1.00_original.html}{\includegraphics[width=5.5in]{../figures/binned_spikes_binSize_1.00_original.png}}

        \caption{z-scores of binned spikes times of all neurons (bin
        size=1~sec, unsorted neurons).  Generated with
        \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doEx1Plotly.py}{this}
        script using its default parameters. Click on the image to see its
        interactive version.}

        \label{fig:zscores_unsorted}
    \end{center}
\end{figure}

If I don't limit the \texttt{zmax} of the heatmap colours become imbalanced due
to a neuron with high firing at one time
(Figure~\ref{fig:zscores_unsorted_noZmax}). 

\begin{figure}[H]
    \begin{center}
        \href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_binSize_1.00_noZmax.html}{\includegraphics[width=5.5in]{../figures/binned_spikes_binSize_1.00_noZmax.png}}

        \caption{z-scores of binned spikes times of all neurons, plotted
        without \texttt{zmax} (bin size=1~sec, unsorted neurons). Generated
        with
        \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doEx1Plotly.py}{this}
        script using its default parameters. Click on the image to see its
        interactive version.}

        \label{fig:zscores_unsorted_noZmax}
    \end{center}
\end{figure}

If I don't z-score the binned spikes colours become imbalanced due to neurons that
have large mean firing rate (Figure~\ref{fig:zscores_unsorted_noZscored}).

\begin{figure}[H]
    \begin{center}
        \href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_binSize_1.00_noZscored.html}{\includegraphics[width=5.5in]{../figures/binned_spikes_binSize_1.00_noZscored.png}}

        \caption{Non-zscored binned spikes times of all neurons (bin
        size=1~sec, unsorted neurons).  Generated with
        \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doEx1Plotly.py}{this}
        script using its default parameters. Click on the image to see its
        interactive version.}

        \label{fig:zscores_unsorted_noZscored}
    \end{center}
\end{figure}

\section*{Exercise 2: application of the SVD to z-scored binned spikes}

Figure~\ref{fig:zscores_vh0Sorted} plots the same z-scored binned spikes of
Figure~\ref{fig:zscores_unsorted}, but with neurons ordered according to their
weight along the first right singular vector.


\begin{figure}[H]
    \begin{center}
        \href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_svd_binSize_1.00_vh0Sorted.html}{\includegraphics[width=5.5in]{../figures/binned_spikes_svd_binSize_1.00_vh0Sorted.png}}

        \caption{Same as Figure~\ref{fig:zscores_unsorted}, but neurons have
        been sorted according to their weight along the first left singular
        vector. The black vertical line indicates the last response time of the
        subject. Generated with
        \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doEx2Plotly.py}{this}
        script using its default parameters. Click on the image to see its
        interactive version.}

        \label{fig:zscores_vh0Sorted}
    \end{center}
\end{figure}

The first left right singular vector (scaled by the corresponding entry in the
first right singular vector) gives the temporal profile of the best rank-one approximation of the
binned spikes of any neuron.
%
Figure~\ref{fig:firstLeftSingularVector} plots in blue a part of the the first
left singular vector between 400 and 650~seconds. The block vertical lines
indicate subject response times. Interestingly, we see that this approximation
of the binned spikes times tends to peak immediately after the subject response
times. This suggest a synchronisation between neurons' spikes and subject's
responses.

\begin{figure}[H]
    \begin{center}
        \href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_svd_binSize_1.00_uFirstCol.html}{\includegraphics[width=5.5in]{../figures/binned_spikes_svd_binSize_1.00_uFirstCol_segment.png}}

        \caption{Part of the first left singular vector (blue trace) and subject response times
        (black vertical lines). This figure suggests a synchronisation between
        neurons' spikes and subjects responses (see text).
        Generated with
        \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doEx2Plotly.py}{this}
        script using its default parameters. Click on the image to see its
        interactive version.}

        \label{fig:firstLeftSingularVector}
    \end{center}
\end{figure}


The nth entry of the first right singular vector gives us the weight of the
first left singular vector to approximate the z-scores of the binned spikes of
neuron $n$.  Figure~\ref{fig:histEntriesFirstRightSingularVector} plots the
histogram of entries of the first right singular vector. We see
weights as positive as 0.13, corresponding to neurons with z-scored binned
spikes correlated to the first left singular vector. We also see weights
as negative as -0.12, corresponding to neurons with z-scored binned spikes anti
correlated to the first left singular vector.

\begin{figure}[H]
    \begin{center}
        \href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_svd_binSize_1.00_uFirstColWeight.html}{\includegraphics[width=5.5in]{../figures/binned_spikes_svd_binSize_1.00_uFirstColWeight.png}}

        \caption{Histogram of entries in the first right left singular vector.
        Generated with
        \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doEx2Plotly.py}{this}
        script using its default parameters. Click on the image to see its
        interactive version.}

        \label{fig:histEntriesFirstRightSingularVector}
    \end{center}
\end{figure}

The weight of the first left singular vector on the z-scored binned spikes of
the neurons near the top of Figure~\ref{fig:zscores_vh0Sorted} is large and
positive. We see vertical red stripes on the z-scores of these neurons,
indicating their strong synchronisation with the response times of the subject.
%
Before the time of the last response of the subject (black vertical line)
z-scores tend to be positive (i.e., binned spikes larger than their mean), but
after the last response of the subject z-scores tend to be negative.
%
Moving the computer cursor over the top of the figure shows that most of these
neurons belong to the primary motor cortex\footnote{areas: MOp5 (layer 5),
MOp6a (layer 6a), MOp6b (layer 6b)} and striatum\footnote{areas: CP
(caudoputamen), STR (striatum)}.

The opposite happens to neurons near the bottom of
Figure~\ref{fig:zscores_vh0Sorted}. For these neurons the weight of the first
left singular vector on their z-scored binned spikes is large and negative. We
don't see vertical stripes on their z-scores. Before the time of the last
response of the subject (black vertical line) z-scores tend to be negative
(i.e., binned spikes lower than their mean), but after the last response of the
subject z-scores tend to be positive.
%
Moving the computer cursor over the top of the figure shows that most neurons
belong to the pallidum\footnote{area BST (bed nuclei of the stria terminalis)}.

\pagebreak
\begin{appendices}

\section{Notes on the SVD}
\label{sec:notesOnTheSVD}

    \begin{definition}[The SVD]
        Given $M\in\mathbb{C}^{m\times n}$, a singular value decomposition (SVD)
        of $M$ is a factorisation:

        \begin{align*}
            M = USV^*
        \end{align*}

        where

        \begin{align*}
            U &\in \mathbb{C}^{m\times m}\quad\text{is unitary,}\\
            V &\in \mathbb{C}^{n\times n}\quad\text{is unitary,}\\
            S &\in \mathbb{C}^{m\times n}\quad\text{is diagonal.}
        \end{align*}

        In addition, it is assumed that the diagonal entries $s_k$ of $S$ are
        nonnegative and in nonincreasing order; that is, $s_1\ge
        s_2\ge\ldots\ge s_p\ge 0$, where $p=\min(m, n)$.
    \end{definition}

    \begin{definition}[Rank of a matrix]

        The column rank of a matrix is the dimension of the space spanned by
        its columns. Similarly, the row rank of a matrix is the dimension of
        the space spanned by its rows. The column rank of a matrix is always
        equal to its row rank. This is a corollary of the SVD. So we refer to
        this number simply as the rank of a matrix.

        \label{def:rank}
    \end{definition}

    The rank of a matrix can be interpreted as a measure of the complexity of
    the matrix. Matrices with lower rank are simpler than those with larger
    rank.

    The SVD decomposes a matrix as a sum of rank-one (i.e., very simple)
    matrices. 

    \begin{align*}
        M = \sum_{k=1}^rs_k\mathbf{u}_k\mathbf{v}_k^*
    \end{align*}

    There are multiple other decompositions as sums of rank-one matrices. If
    $M\in\mathbb{C}^{m\times n}$, then it can be decomposed as a sum of $m$
    rank-one matrices given by its rows (i.e.,
    $M=\sum_{i=1}^m\mathbf{e}_i\mathbf{m}_{i,\cdot}^*$, where $\mathbf{e}_i$ is
    the m-dimensional canonical unit vector, and $\mathbf{m}_{i,\cdot}$ is the ith row
    of $M$), or as a sum of $n$ rank-one matrices given by its columns (i.e.,
    $M=\sum_{j=1}^n\mathbf{m}_{\cdot,j}\mathbf{e}_j^*$, where $\mathbf{e}_j$ is
    the n-dimensional canonical unit vector, and $\mathbf{m}_{\cdot,j}$ is the jth
    column of $M$), or a sum of $mn$ rank-one matrices each containing only one
    non-zero element (i.e., $M=\sum_{i=1}^m\sum_{j=1}^nm_{ij}E_{ij}$, where
    $E_{ij}$ is the matrix with all entries equal to zero, except the $ij$
    entry that is one, and $m_{ij}$ is the entry of $M$ at position ij).

    A unique characteristic of the SVD compared to these other decompositions
    is that, if the rank of a matrix is $r$, then its SVD yields optimal
    approximations of lower rank $\nu$, for $\nu=1,\ldots,r$, as shown by
    Theorem~\ref{thm:eckart-young-mirsky}.

    \begin{definition}[Frobenius norm]
        The Frobenius norm of matrix $M\in\mathbb{C}^{m\times n}$ is

        \begin{align*}
            \|M\|_F=\left(\sum_{i=1}^m\sum_{j=1}^nm_{ij}^2\right)^{1/2}
        \end{align*}

    \end{definition}

    Note that

    \begin{align}
        \|M\|_F=\sqrt{tr(M^*M)}=\sqrt{tr(MM^*)}
        \label{eq:frobeniusAsTrace}
    \end{align}

    \begin{lemma}[Orthogonal matrices preserve the Frobenius norm]
        Let $M\in\mathbb{C}^{m\times n}$ and let $P\in\mathbb{C}^{m\times m}$
        and $Q\in\mathbb{C}^{n\times n}$ be orthogonal matrices. Then

        \begin{align*}
            \|PMQ\|_F=\|M\|_F
        \end{align*}

        \label{lemma:orthogonalPreserveF}
    \end{lemma}

    \begin{proof}
        \begin{align}
            \|PMQ\|_F&=\sqrt{tr((PMQ)(PMQ)^*)}=\sqrt{tr(PMQQ^*M^*P^*)}=\sqrt{tr(PMM^*P^*)\label{eq:frobInvLine1}}\\
                     &=\sqrt{tr(P^*PMM^*)}=\sqrt{tr(MM^*)}=\|M\|_F\label{eq:frobInvLine2}
        \end{align}
        Notes:
        \begin{enumerate}
            \item The first equality in Eq.~\ref{eq:frobInvLine1} follows
                Eq.~\ref{eq:frobeniusAsTrace}.
            \item The second equality in Eq.~\ref{eq:frobInvLine1} uses the fact
                that $(AB)^*=B^*A^*$.
            \item The third equality in Eq.~\ref{eq:frobInvLine1} holds because
                $Q$ is orthogonal (i.e., $QQ^*=I$).
            \item The first equality in Eq.~\ref{eq:frobInvLine2} uses the
                cyclic property of the trace (i.e., tr(ABC)=tr(CAB)).
            \item The first equality in Eq.~\ref{eq:frobInvLine2} holds by the
                orthogonality of $P$.
            \item The last equality in Eq.~\ref{eq:frobInvLine2} again applies
                Eq.~\ref{eq:frobeniusAsTrace}.
        \end{enumerate}
    \end{proof}

    A direct consequence of Lemma~\ref{lemma:orthogonalPreserveF} is that the
    Frobenius norm of any matrix $M=USV^*$ is

    \begin{align*}
        \|M\|_F=\|USV^*\|_F=\|S\|_F=\sqrt{\sum_{k=1}^rs_k^2}
    \end{align*}

    Another consequence of Lemma~\ref{lemma:orthogonalPreserveF} is 
    the error in approximating a matrix $M$ of rank $r$ with its truncated
    SVD of rank $\nu$ (i.e., $M_\nu=\sum_{k=1}^\nu s_k\mathbf{u}_k\mathbf{v}_k^*$) is

    \begin{align}
        \|M-M_\nu\|_F=\|\sum_{k=1}^rs_k\mathbf{u}_k\mathbf{v}_k^*-\sum_{k=1}^\nu
        s_k\mathbf{u}_k\mathbf{v}_k^*\|_F=\|\sum_{k={\nu+1}}^rs_k\mathbf{u}_k\mathbf{v}_k^*\|_F=\sqrt{\sum_{k=\nu+1}^rs_k^2}\label{eq:truncSVDerror}
    \end{align}

    \begin{theorem}[Eckart-Young-Mirsky]
        Let $M\in\mathbb{C}^{m\times n}$ be of rank r with singular value
        decomposition $M=\sum_{k=1}^rs_k\mathbf{u}_k\mathbf{v}_k^*$. For
        any $\nu$ with $0\leq\nu\leq r$, define

        
        \begin{align*}
            M_\nu=\sum_{k=1}^\nu s_k\mathbf{u}_k\mathbf{v}_k^*
        \end{align*}

        Then

        \begin{align}
            \|M-M_\nu\|_F=\inf_{\substack{\tilde{M}\in\mathbb{C}^{m\times n}\\\text{rank}(\tilde{M})\leq\nu}}\|M-\tilde{M}\|_F=\sqrt{\sum_{k=\nu+1}^rs_k^2}\label{eq:errorFNorm}
        \end{align}

        \label{thm:eckart-young-mirsky}
    \end{theorem}

    \begin{proof}
        We use the Weyl's inequality that relates the singular values of a sum
        of two matrices to the singular values of each of these matrices.
        Precisely, if $X,Y\in\mathbb{C}^{m\times n}$ and $s_i(X)$ is the ith
        singular value of $X$, then

        \begin{align}
            s_{i+j-1}(X+Y)\leq s_i(X)+s_j(Y)
            \label{eq:weylsInequality}
        \end{align}

        Let $\tilde{M}$ be a matrix of rank at most $\nu$. Applying
        Eq.~\ref{eq:weylsInequality} to $X=M-\tilde{M}$, $Y=\tilde{M}$ and
        $j-1=\nu$ we obtain

        \begin{align}
            s_{i+\nu}(M)\leq s_i(M-\tilde{M})+s_{\nu+1}(\tilde{M})=s_i(M-\tilde{M})\label{eq:svMandMerror}
        \end{align}

        The last equality in Eq.~\ref{eq:svMandMerror} holds because $\tilde{M}$
        has rank less or equal to $\nu$, and therefore its $\nu+1$ singular value is zero.

        \begin{align}
            \|M-M_\nu\|_F^2&=\sum_{j=\nu+1}^rs_j^2(M)=\sum_{i=1}^{r-\nu}s_{i+\nu}^2(M)\leq\sum_{i=1}^{r-\nu}s_i^2(M-\tilde{M})\leq\sum_{i=1}^{\min(m,n)}s_i^2(M-\tilde{M})\label{eq:final1}\\
                           &=\|M-\tilde{M}\|_F^2\label{eq:final2}
        \end{align}

        Notes:
        \begin{enumerate}
            \item The first equality in Eq.~\ref{eq:final1} holds by
                Eq.~\ref{eq:truncSVDerror}.
            \item The second equality in Eq.~\ref{eq:final1} used the change of
                variables $i=j-\nu$.
            \item The first inequality in Eq.~\ref{eq:final1} used
                Eq.~\ref{eq:svMandMerror}
            \item The last inequality in Eq.~\ref{eq:final1} is true because
                $r-\nu\leq\min(m,n)$ and adding squared singular values to the sum in
                the left hand side only increases this sum.
            \item The equality in Eq.~\ref{eq:final2} again holds by
                Eq.~\ref{eq:errorFNorm} and by the fact that singular values of
                index larger than the rank of a matrix are zero.
        \end{enumerate}

        The last equality in Eq.~\ref{eq:errorFNorm} follows from
        Eq.~\ref{eq:truncSVDerror}.

    \end{proof}

\section{Verification of the Eckart-Young-Mirsky theorem}
\label{sec:verificationEckartYoungMirsky}

I found it almost unbelievable that Theorem~\ref{thm:eckart-young-mirsky} allows
us to compute the error that will be achieved by a low-rank approximation by
just using the singular values of the matrix to be approximated, and without
the need to calculating this approximation.

To verify Theorem~\ref{thm:eckart-young-mirsky}, for different ranks $\nu$, I
computed truncated SVD approximations to the matrix shown in
Figure~\ref{fig:zscores_vh0Sorted}. For each of these approximations, I
calculated the empirical error (i.e., the Frobenius norm of the difference between
the matrix and the approximation) and the analytical error (i.e., the sum of
singular values in Eq.~\ref{eq:errorFNorm}). As shown in
Figures~\ref{fig:truncatedSVD-rank1}-\ref{fig:truncatedSVD-rank20}
the empirical and analytical errors are almost identical.

% Figure~\ref{fig:singularValues} plots the singular value of the matrix in
% Figure~\ref{fig:zscores_vh0Sorted}. We see large reductions in singular values
% upto the xth singular value. Therefore, we expect to see large improvements in
% the approximation error as we increase the rank of the truncated SVD until rank
% x, but not later.

\def\i{1}
    \begin{figure}
        \begin{center}

            \href{http://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_truncatedSVD_binSize_1.00_nComponents_\i.html}{\includegraphics[width=5in]{../figures/binned_spikes_truncatedSVD_binSize_1.00_nComponents_\i.png}}

            \caption{Low-rank approximation of the image in
            Figure~\ref{fig:zscores_vh0Sorted} using a truncated SVD or rank
            \i. The title reports the empirical and analytical errors of the
            reconstruction. The empirical error is the Frobenius norm of the
            difference between the low-rank approximation and the image in
            Figure~\ref{fig:zscores_vh0Sorted}. The analytical error is
            computed from the singular values of the image in
            Figure~\ref{fig:zscores_vh0Sorted} using Eq.~\ref{eq:errorFNorm}.
            Generated with
            \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doPlotTruncatedSVD.py}{this}
            script with
            \href{https://github.com/joacorapela/neuroinformatics23/blob/master/worksheets/ws5/mySolution/code/scripts/doPlotTruncatedSVD.csh}{these}
            parameters.  Click on the image to access its interactive version.}

            \label{fig:truncatedSVD-rank\i}

        \end{center}
    \end{figure}
\foreach \i in {2,3,...,20}{
    \begin{figure}
        \begin{center}

            \href{http://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2023/ws5/figures/binned_spikes_truncatedSVD_binSize_1.00_nComponents_\i.html}{\includegraphics[width=5in]{../figures/binned_spikes_truncatedSVD_binSize_1.00_nComponents_\i.png}}

            \caption{Low-rank approximation of the image in
            Figure~\ref{fig:zscores_vh0Sorted} using a truncated SVD or rank
            \i. Same format as that in Figure~\ref{fig:truncatedSVD-rank1}.
            Click on the image to
            access its interactive version.}

            \label{fig:truncatedSVD-rank\i}

        \end{center}
    \end{figure}
}

\end{appendices}

% x weights
% x interpreation of vh0Sorted
%   . last response time at 31xx (add vline to heatmap)
%   . neurons sync to response times \in motor cortex layer ?? and striatrum  (STR, ,,,)
%   . neurons not sync to response times \in pallidum
% x svd interpretation as a sum of of rank 1 matrices
% . results with bin_size = 0.05

\end{document}
